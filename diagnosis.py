# step1_diagnosis.py
import pandas as pd
import numpy as np
import joblib
from pathlib import Path
import glob

print("ğŸ” å¼€å§‹è¯Šæ–­é—®é¢˜...")

# 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
print("\n1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§:")
files_to_check = [
    "banking_features_ai.csv",
    "*.pkl"  # RFæ¨¡å‹æ–‡ä»¶
]

features_file = "banking_features_ai.csv"
if Path(features_file).exists():
    print(f"âœ… ç‰¹å¾æ–‡ä»¶å­˜åœ¨: {features_file}")
    features_data = pd.read_csv(features_file, index_col=0, parse_dates=True)
    print(f"   - ç‰¹å¾æ•°æ®å½¢çŠ¶: {features_data.shape}")
    print(f"   - æ—¥æœŸèŒƒå›´: {features_data.index[0]} åˆ° {features_data.index[-1]}")

    # æ£€æŸ¥æ¯ä¸ªè‚¡ç¥¨çš„ç‰¹å¾æ•°é‡
    tickers = ['AXP', 'BAC', 'BK', 'C', 'CB', 'COF', 'GS', 'JPM', 'MS', 'PNC', 'SCHW', 'STT', 'TFC', 'USB', 'WFC']
    for ticker in tickers:
        ticker_features = [col for col in features_data.columns if col.startswith(f'{ticker}_')]
        print(f"   - {ticker}: {len(ticker_features)} ä¸ªç‰¹å¾")
else:
    print(f"âŒ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {features_file}")

# 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
print("\n2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶:")
model_files = glob.glob("rf_v4_complete_*.pkl")
print(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹æ–‡ä»¶:")

for model_file in model_files[:3]:  # åªæ£€æŸ¥å‰3ä¸ª
    ticker = Path(model_file).stem.split('_')[-1]
    print(f"\næ£€æŸ¥æ¨¡å‹: {ticker}")

    try:
        model_data = joblib.load(model_file)
        print(f"  âœ… å¯ä»¥åŠ è½½")

        if 'model' in model_data:
            model = model_data['model']
            print(f"  - æ¨¡å‹ç±»å‹: {type(model).__name__}")

            if hasattr(model, 'n_features_in_'):
                print(f"  - æœŸæœ›ç‰¹å¾æ•°: {model.n_features_in_}")

        if 'scaler' in model_data:
            scaler = model_data['scaler']
            has_scale = hasattr(scaler, 'scale_') and scaler.scale_ is not None
            print(f"  - ç¼©æ”¾å™¨çŠ¶æ€: {'å·²è®­ç»ƒ' if has_scale else 'æœªè®­ç»ƒ'}")

    except Exception as e:
        print(f"  âŒ åŠ è½½å¤±è´¥: {e}")

# 3. ç®€å•æµ‹è¯•é¢„æµ‹
print("\n3. æµ‹è¯•æ¨¡å‹é¢„æµ‹:")
if len(model_files) > 0 and Path(features_file).exists():
    try:
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ¨¡å‹æµ‹è¯•
        test_model_file = model_files[0]
        test_ticker = Path(test_model_file).stem.split('_')[-1]

        model_data = joblib.load(test_model_file)
        model = model_data['model']

        # è·å–å¯¹åº”ç‰¹å¾
        ticker_features = [col for col in features_data.columns if col.startswith(f'{test_ticker}_')]

        if len(ticker_features) > 0:
            # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¥æœŸçš„æ•°æ®æµ‹è¯•
            test_date = features_data.index[-1]
            test_features = features_data.loc[test_date, ticker_features].values.reshape(1, -1)

            # å¤„ç†NaN
            if np.any(np.isnan(test_features)):
                print(f"  âš ï¸ å‘ç°NaNå€¼ï¼Œå¡«å……ä¸º0")
                test_features = np.nan_to_num(test_features, nan=0)

            print(f"  æµ‹è¯•ç‰¹å¾å½¢çŠ¶: {test_features.shape}")

            # å°è¯•é¢„æµ‹
            if hasattr(model, 'predict_proba'):
                pred = model.predict_proba(test_features)
                print(f"  âœ… é¢„æµ‹æˆåŠŸ: {pred}")
            else:
                pred = model.predict(test_features)
                print(f"  âœ… é¢„æµ‹æˆåŠŸ: {pred}")

        else:
            print(f"  âŒ æ²¡æœ‰æ‰¾åˆ° {test_ticker} çš„ç‰¹å¾")

    except Exception as e:
        print(f"  âŒ é¢„æµ‹æµ‹è¯•å¤±è´¥: {e}")

print("\nğŸ è¯Šæ–­å®Œæˆ!")
print("\nä¸‹ä¸€æ­¥:")
print("1. å¦‚æœæ¨¡å‹æ–‡ä»¶æ­£å¸¸ï¼Œè¿è¡Œ step2_fix_prediction.py")
print("2. å¦‚æœæ¨¡å‹æ–‡ä»¶æœ‰é—®é¢˜ï¼Œå¯èƒ½éœ€è¦é‡æ–°è®­ç»ƒ")