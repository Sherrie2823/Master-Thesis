# xgboost_enhanced_production.py - æç®€ç¨³å®šç‰ˆ

"""
æç®€ç¨³å®šçš„XGBoostå¢å¼ºä¼˜åŒ–å™¨
- é¿å…å¤æ‚çš„æ•°å€¼ä¼˜åŒ–
- ä½¿ç”¨ç®€å•ä½†ç¨³å®šçš„æƒé‡åˆ†é…
- ä¸“æ³¨äºXGBoostä¿¡å·çš„æœ‰æ•ˆåˆ©ç”¨
"""

import os
import pandas as pd
import numpy as np
import joblib
import cloudpickle
from pathlib import Path
from datetime import datetime
import warnings
from typing import Dict  # æ·»åŠ ç±»å‹æç¤ºå¯¼å…¥
from scipy import stats
import scipy.stats as stats
from joblib import load as joblib_load






# å¯¼å…¥åŸºç¡€ä¼˜åŒ–å™¨
from complete_traditional_methods import RollingPortfolioOptimizer

warnings.filterwarnings('ignore')


class SimpleXGBOptimizer(RollingPortfolioOptimizer):
    """æç®€XGBoostå¢å¼ºä¼˜åŒ–å™¨"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.xgb_models = {}
        self.scalers = {}
        self.feature_selectors = {}
        self.features_data = None
        self.signal_history = {}
        self.optimal_thresholds = {}
        self.calibration_methods = {}
        self.asset_names = set(col.split('_')[0] for col in self.returns.columns)

        print("ğŸš€ å¯åŠ¨æç®€XGBoostä¼˜åŒ–å™¨...")
        self._load_xgb_models()
        self._load_features_data()

    def _load_xgb_models(self):
        """åŠ è½½ XGBoost æ¨¡å‹ï¼ˆå…¼å®¹ .skops å’Œ .pkl ä¸¤ç§æ ¼å¼ï¼‰"""
        model_files = list(Path(".").rglob("xgb_v5_complete_*.pkl"))
        
        for f in model_files:
            ticker = f.stem.split("_")[-1]
            model_dict = joblib_load(f)
            self.xgb_models[ticker] = model_dict
            
            print(f"{ticker} åŠ è½½æˆåŠŸ")
        print(f"âœ… å…±åŠ è½½ {len(self.xgb_models)} ä¸ª XGBoost æ¨¡å‹")
    

    def _load_features_data(self):
        """åŠ è½½ç‰¹å¾æ•°æ®"""
        # å°è¯•å¤šç§å¯èƒ½çš„ç‰¹å¾æ–‡ä»¶å
        possible_files = [
            "banking_returns.csv",  # XGBoost V5ä½¿ç”¨çš„ç‰¹å¾æ–‡ä»¶
            "banking_features_ai.csv",
            "features.csv"
        ]
        
        for filename in possible_files:
            features_files = list(Path(".").glob(filename))
            if features_files:
                self.features_data = pd.read_csv(features_files[0], index_col=0, parse_dates=True)
                print(f"âœ… åŠ è½½ç‰¹å¾æ•°æ®: {self.features_data.shape} from {filename}")
                return
                
        print("âš ï¸ æœªæ‰¾åˆ°ç‰¹å¾æ•°æ®æ–‡ä»¶")

    def _simple_xgb_prediction(self, ticker: str, trade_date: pd.Timestamp) -> float:
        """ç®€å•XGBoosté¢„æµ‹"""
        if ticker not in self.xgb_models or self.features_data is None:
            if ticker not in self.xgb_models:
                print(f"{ticker}: æ— XGBoostæ¨¡å‹")
            if self.features_data is None:
                print("ç‰¹å¾æ•°æ®æœªåŠ è½½")
            return 0.0

        # è·å–æ¨¡å‹æ•°æ®

        model_data            = self.xgb_models[ticker]
        calibrated_model = model_data.get('calibrated_model')
        model           = model_data.get('model')
        scaler           = model_data.get('scaler')
        selected_features= model_data.get('selected_features', [])
        optimal_threshold= model_data.get('optimal_threshold', 0.5)
        
        if not selected_features:
            print(f"{ticker}: æ— é€‰æ‹©ç‰¹å¾")
            return 0.0

        # è·å–å¯ç”¨æ—¥æœŸ
        available_dates = self.features_data.index[self.features_data.index <= trade_date]
        if len(available_dates) == 0:
            print(f"{ticker}: æ— å¯ç”¨æ—¥æœŸ")
            return 0.0

        actual_date = available_dates[-1]
        
        # æå–ç‰¹å¾
        try:
            # 1) å…ˆæ‹¿æ•´è¡Œï¼ˆå¯èƒ½å°‘åˆ—ï¼‰ï¼Œç„¶å reindex åˆ°å®Œæ•´çš„ selected_features
            row = self.features_data.loc[actual_date]
            row = row.reindex(selected_features)

    # 2) å¡«å……ç¼ºå¤±å€¼ï¼šå‘å‰ã€å‘åã€æœ€åç»Ÿä¸€ç”¨ 0
            row = row.fillna(method='ffill') \
                     .fillna(method='bfill') \
                     .fillna(0)

    # 3) æ‹¿åˆ° numpy å‘é‡
            feature_vector = row.values

    # å¦‚æœæœ‰ scalerï¼Œåšæ ‡å‡†åŒ–
            if scaler is not None:
                feature_vector = scaler.transform(feature_vector.reshape(1, -1))[0]
            
            feature_vector = feature_vector.reshape(1, -1)

        except Exception as e:
            print(f"{ticker}: ç‰¹å¾æå–å¤±è´¥ {e}")
            return 0.0

        try:
            # ä½¿ç”¨æ ¡å‡†åçš„æ¨¡å‹è¿›è¡Œé¢„æµ‹
            if calibrated_model is not None:
                prob = calibrated_model.predict_proba(feature_vector)[0]
                print(f"[{trade_date.date()}] {ticker} calibrated_proba: {prob}")
                if len(prob) > 1:
                    raw_signal = prob[1]  # ä¸Šæ¶¨æ¦‚ç‡
                else:
                    raw_signal = prob[0]
                    
                # ä½¿ç”¨æœ€ä¼˜é˜ˆå€¼è½¬æ¢ä¸ºä¿¡å·
                signal = (raw_signal - optimal_threshold) * 2  # [-1, 1]èŒƒå›´
                
            elif model is not None and hasattr(model, 'predict_proba'):
                prob = model.predict_proba(feature_vector)[0]
                print(f"[{trade_date.date()}] {ticker} model_proba: {prob}")
                if len(prob) > 1:
                    signal = prob[1] - 0.5  # ä¸Šæ¶¨æ¦‚ç‡å‡å»0.5
                else:
                    signal = prob[0] - 0.5
                    
            else:
                print(f"{ticker}: æ¨¡å‹é¢„æµ‹å¤±è´¥")
                return 0.0

            # é™åˆ¶ä¿¡å·èŒƒå›´
            signal = np.clip(signal, -0.3, 0.3)
            print(f"[{trade_date.date()}] {ticker} signal: {signal:.4f}")
            return signal

        except Exception as e:
            print(f"{ticker}: é¢„æµ‹å¤±è´¥ {e}")
            return 0.0

    def generate_xgb_signals(self, trade_date: pd.Timestamp) -> pd.Series:
        """ç”ŸæˆXGBoostä¿¡å·"""
        print(f"ğŸ¯ ç”ŸæˆXGBoostä¿¡å·: {trade_date.date()}")

        signals = {}
        active_count = 0

        asset_names = set(col.split('_')[0] for col in self.returns.columns)
        for ticker in asset_names:
            signal = self._simple_xgb_prediction(ticker, trade_date)
            signals[ticker] = signal
            
            if abs(signal) > 0.01:
                active_count += 1

        print(f"  âœ… {active_count}/{len(signals)} ä¸ªæ´»è·ƒä¿¡å·")

        # å­˜å‚¨ä¿¡å·å†å²
        self.signal_history[trade_date] = {
            'signals': signals.copy(),
            'active_count': active_count
        }

        return pd.Series(signals, index=sorted(asset_names))

    def optimize_simple_xgb_enhanced(self, returns_data: pd.DataFrame,
                                     trade_date: pd.Timestamp) -> Dict:
        """ç®€å•çš„XGBoostå¢å¼ºä¼˜åŒ–"""
        print(f"ğŸ”§ ç®€å•XGBoostå¢å¼ºä¼˜åŒ–: {trade_date.date()}")

        # è·å–XGBoostä¿¡å·
        xgb_signals = self.generate_xgb_signals(trade_date)

        # ğŸ”§ ç®€å•æ–¹æ³•ï¼šåŸºäºä¿¡å·å¼ºåº¦åˆ†é…æƒé‡
        n_assets = len(self.asset_names)

        # åŸºç¡€ç­‰æƒé‡
        base_weights = np.ones(n_assets) / n_assets
        print(f"n_assets: {n_assets}, åŸºç¡€æƒé‡: {base_weights}")

        # XGBoostä¿¡å·è°ƒæ•´
        signal_values = xgb_signals.values

        # å°†ä¿¡å·è½¬æ¢ä¸ºæƒé‡è°ƒæ•´
        # æ­£ä¿¡å·å¢åŠ æƒé‡ï¼Œè´Ÿä¿¡å·å‡å°‘æƒé‡
        weight_adjustments = signal_values * 0.15  # 15%çš„æœ€å¤§è°ƒæ•´ï¼ˆæ¯”RFç¨å¤§ï¼‰

        # æ–°æƒé‡ = åŸºç¡€æƒé‡ + è°ƒæ•´
        new_weights = base_weights + weight_adjustments

        # ç¡®ä¿æƒé‡ä¸ºæ­£
        new_weights = np.maximum(new_weights, 0.02)  # æœ€å°2%

        # ç¡®ä¿æƒé‡ä¸è¶…è¿‡25%
        new_weights = np.minimum(new_weights, 0.25)

        # æ ‡å‡†åŒ–ä½¿å¾—å’Œä¸º1
        new_weights = new_weights / new_weights.sum()

        # ç®€å•çš„æ€§èƒ½ä¼°è®¡
        # ä½¿ç”¨å†å²æ”¶ç›Šç‡ä¼°è®¡
        hist_returns = returns_data.mean() * 252
        portfolio_return = np.sum(new_weights * hist_returns)

        # ç®€å•çš„é£é™©ä¼°è®¡
        returns_cov = returns_data.cov() * 252
        portfolio_vol = np.sqrt(np.dot(new_weights, np.dot(returns_cov.values, new_weights)))

        # Sharpeæ¯”ç‡
        sharpe = (portfolio_return - self.risk_free_rate) / portfolio_vol if portfolio_vol > 0 else 0

        active_signals = len([s for s in signal_values if abs(s) > 0.01])

        print(f"  âœ… ç®€å•XGBoostä¼˜åŒ–æˆåŠŸ: Sharpe={sharpe:.3f}, æ´»è·ƒä¿¡å·={active_signals}")

        return {
            'weights': new_weights,
            'performance': (portfolio_return, portfolio_vol, sharpe),
            'method': 'Simple XGBoost Enhanced',
            'xgb_signals_used': active_signals,
            'success': True
        }

    def optimize_xgb_momentum(self, returns_data: pd.DataFrame,
                              trade_date: pd.Timestamp) -> Dict:
        """XGBoost + åŠ¨é‡ç»„åˆç­–ç•¥"""
        print(f"ğŸ”§ XGBoost+åŠ¨é‡ç­–ç•¥: {trade_date.date()}")

        # XGBoostä¿¡å·
        xgb_signals = self.generate_xgb_signals(trade_date)

        # åŠ¨é‡ä¿¡å·ï¼ˆ3ä¸ªæœˆï¼‰
        momentum_window = min(63, len(returns_data))  # 3ä¸ªæœˆæˆ–å¯ç”¨æ•°æ®
        momentum_returns = returns_data.tail(momentum_window).mean()

        # æ ‡å‡†åŒ–åŠ¨é‡ä¿¡å·
        momentum_signals = (momentum_returns - momentum_returns.mean()) / momentum_returns.std()
        momentum_signals = momentum_signals.fillna(0)

        # ç»„åˆä¿¡å· (60% XGBoost + 40% åŠ¨é‡ï¼ŒXGBoostæƒé‡ç¨é«˜)
        combined_signals = 0.6 * xgb_signals + 0.4 * momentum_signals

        # åŸºäºç»„åˆä¿¡å·åˆ†é…æƒé‡
        n_assets = len(returns_data.columns)

        # å°†ä¿¡å·è½¬æ¢ä¸ºæƒé‡å¾—åˆ†
        signal_scores = combined_signals.values

        # å°†è´Ÿä¿¡å·è®¾ä¸º0ï¼ˆåªåšå¤šï¼‰
        positive_scores = np.maximum(signal_scores, 0)

        if positive_scores.sum() > 0:
            # åŸºäºæ­£ä¿¡å·åˆ†é…æƒé‡
            weights = positive_scores / positive_scores.sum()

            # é™åˆ¶å•ä¸ªæƒé‡
            weights = np.minimum(weights, 0.25)  # æœ€å¤§25%
            weights = np.maximum(weights, 0.02)  # æœ€å°2%

            # é‡æ–°æ ‡å‡†åŒ–
            weights = weights / weights.sum()
        else:
            # å¦‚æœæ²¡æœ‰æ­£ä¿¡å·ï¼Œç­‰æƒé‡
            weights = np.ones(n_assets) / n_assets

        # æ€§èƒ½ä¼°è®¡
        hist_returns = returns_data.mean() * 252
        portfolio_return = np.sum(weights * hist_returns)

        returns_cov = returns_data.cov() * 252
        portfolio_vol = np.sqrt(np.dot(weights, np.dot(returns_cov.values, weights)))

        sharpe = (portfolio_return - self.risk_free_rate) / portfolio_vol if portfolio_vol > 0 else 0

        active_signals = len([s for s in xgb_signals.values if abs(s) > 0.01])

        print(f"  âœ… XGBoost+åŠ¨é‡æˆåŠŸ: Sharpe={sharpe:.3f}, XGBoostä¿¡å·={active_signals}")

        return {
            'weights': weights,
            'performance': (portfolio_return, portfolio_vol, sharpe),
            'method': 'XGBoost + Momentum',
            'xgb_signals_used': active_signals,
            'success': True
        }

    def optimize_xgb_risk_parity(self, returns_data: pd.DataFrame,
                                 trade_date: pd.Timestamp) -> Dict:
        """XGBoostä¿¡å·å¢å¼ºçš„é£é™©å¹³ä»·ç­–ç•¥"""
        print(f"ğŸ”§ XGBoosté£é™©å¹³ä»·ç­–ç•¥: {trade_date.date()}")

        # XGBoostä¿¡å·
        xgb_signals = self.generate_xgb_signals(trade_date)

        # è®¡ç®—é£é™©å¹³ä»·åŸºç¡€æƒé‡
        returns_cov = returns_data.cov() * 252
        inv_vol = 1 / np.sqrt(np.diag(returns_cov))
        risk_parity_weights = inv_vol / inv_vol.sum()

        # ä½¿ç”¨XGBoostä¿¡å·è°ƒæ•´é£é™©å¹³ä»·æƒé‡
        signal_adjustments = xgb_signals.values * 0.2  # 20%çš„æœ€å¤§è°ƒæ•´

        # è°ƒæ•´åçš„æƒé‡
        adjusted_weights = risk_parity_weights + signal_adjustments

        # ç¡®ä¿æƒé‡çº¦æŸ
        adjusted_weights = np.maximum(adjusted_weights, 0.02)
        adjusted_weights = np.minimum(adjusted_weights, 0.25)
        adjusted_weights = adjusted_weights / adjusted_weights.sum()

        # æ€§èƒ½ä¼°è®¡
        hist_returns = returns_data.mean() * 252
        portfolio_return = np.sum(adjusted_weights * hist_returns)
        portfolio_vol = np.sqrt(np.dot(adjusted_weights, np.dot(returns_cov.values, adjusted_weights)))
        sharpe = (portfolio_return - self.risk_free_rate) / portfolio_vol if portfolio_vol > 0 else 0

        active_signals = len([s for s in xgb_signals.values if abs(s) > 0.01])

        print(f"  âœ… XGBoosté£é™©å¹³ä»·æˆåŠŸ: Sharpe={sharpe:.3f}, XGBoostä¿¡å·={active_signals}")

        return {
            'weights': adjusted_weights,
            'performance': (portfolio_return, portfolio_vol, sharpe),
            'method': 'XGBoost Risk Parity',
            'xgb_signals_used': active_signals,
            'success': True
        }

    def run_simple_optimization(self, max_periods: int = 15):
        """è¿è¡Œç®€å•ä¼˜åŒ–"""
        print("ğŸš€ å¼€å§‹ç®€å•XGBoostä¼˜åŒ–...")

        if not self.rebalance_dates:
            print("âŒ æ²¡æœ‰é‡æ–°å¹³è¡¡æ—¥æœŸ")
            return

        # æµ‹è¯•æœŸæ•°
        test_dates = self.rebalance_dates[:max_periods]
        print(f"ğŸ“… æµ‹è¯• {len(test_dates)} ä¸ªé‡æ–°å¹³è¡¡æœŸ")

        # ç®€åŒ–çš„æ–¹æ³•é›†åˆ
        methods = {
            'equal_weight': self.optimize_equal_weight,
            'simple_xgb_enhanced': self.optimize_simple_xgb_enhanced,
            'xgb_momentum': self.optimize_xgb_momentum,
            'xgb_risk_parity': self.optimize_xgb_risk_parity
        }

        # åˆå§‹åŒ–ç»“æœå­˜å‚¨
        for method_name in methods.keys():
            self.portfolio_results[method_name] = {
                'weights_history': [],
                'returns_history': [],
                'portfolio_values': [100.0],
                'transaction_costs': [],
                'rebalance_dates': [],
                'optimization_results': []
            }

        successful_periods = 0

        # æ‰§è¡Œä¼˜åŒ–
        for i, rebalance_date in enumerate(test_dates):
            print(f"\nğŸ“Š æœŸé—´ {i + 1}/{len(test_dates)}: {rebalance_date.date()}")

            # è·å–å†å²æ•°æ®
            historical_data = self.returns.loc[:rebalance_date].iloc[:-1]

            if len(historical_data) < self.min_history:
                print(f"  âš ï¸ å†å²æ•°æ®ä¸è¶³")
                continue

            period_success = 0

            # æµ‹è¯•æ¯ç§æ–¹æ³•
            for method_name, optimize_func in methods.items():
                try:
                    if method_name == 'equal_weight':
                        result = optimize_func(historical_data)
                    else:
                        result = optimize_func(historical_data, rebalance_date)

                    if result.get('success', False):
                        weights = result['weights']

                        # å­˜å‚¨ç»“æœ
                        self.portfolio_results[method_name]['weights_history'].append(weights)
                        self.portfolio_results[method_name]['rebalance_dates'].append(rebalance_date)
                        self.portfolio_results[method_name]['optimization_results'].append(result)

                        # æ˜¾ç¤ºç»“æœ
                        perf = result['performance']
                        signals = result.get('xgb_signals_used', 0)

                        if signals > 0:
                            print(f"  âœ… {method_name}: Sharpe={perf[2]:.3f}, ä¿¡å·={signals}")
                        else:
                            print(f"  âœ… {method_name}: Sharpe={perf[2]:.3f}")

                        period_success += 1
                    else:
                        print(f"  âŒ {method_name}: å¤±è´¥")
                
                except Exception as e:
                    print(f"  âŒ {method_name}: å¼‚å¸¸ {e}")

            if period_success > 0:
                successful_periods += 1

        print(f"\nğŸ‰ ç®€å•XGBoostä¼˜åŒ–å®Œæˆ: {successful_periods}/{len(test_dates)} æœŸæˆåŠŸ")

        # è®¡ç®—å’Œå¯¼å‡ºæ€§èƒ½
        self._calculate_simple_performance()
        self._export_simple_results()

        return self.portfolio_results

    def _calculate_simple_performance(self):
        """ç®€å•æ€§èƒ½è®¡ç®—"""
        print("ğŸ“Š è®¡ç®—æ€§èƒ½...")

        for method_name, results in self.portfolio_results.items():
            if not results.get('weights_history'):
                continue

            portfolio_values = [100.0]
            weights_history = results['weights_history']
            rebalance_dates = results['rebalance_dates']

            for i in range(len(rebalance_dates)):
                current_weights = weights_history[i]

                # è®¡ç®—åˆ°ä¸‹ä¸€ä¸ªé‡æ–°å¹³è¡¡æ—¥æœŸçš„æ”¶ç›Š
                if i < len(rebalance_dates) - 1:
                    start_date = rebalance_dates[i]
                    end_date = rebalance_dates[i + 1]
                else:
                    start_date = rebalance_dates[i]
                    end_date = self.returns.index[-1]

                period_returns = self.returns.loc[start_date:end_date]

                if len(period_returns) > 1:
                    # è®¡ç®—æ¯æ—¥æŠ•èµ„ç»„åˆæ”¶ç›Š
                    daily_portfolio_returns = period_returns.iloc[1:] @ current_weights

                    # æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼
                    for daily_return in daily_portfolio_returns:
                        if not np.isnan(daily_return):
                            portfolio_values.append(portfolio_values[-1] * (1 + daily_return))

            results['portfolio_values'] = portfolio_values

            if len(portfolio_values) > 1:
                total_return = (portfolio_values[-1] / portfolio_values[0] - 1) * 100
                print(f"  âœ… {method_name}: æ€»æ”¶ç›Š = {total_return:.1f}%")

    def _export_simple_results(self):
        """å¯¼å‡ºç®€å•ç»“æœ"""
        print("ğŸ“ å¯¼å‡ºç»“æœ...")

        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        # æ€§èƒ½å¯¹æ¯”
        performance_data = []

        for method_name, results in self.portfolio_results.items():
            if results.get('portfolio_values') and len(results['portfolio_values']) > 1:
                values = results['portfolio_values']
                total_return = (values[-1] / values[0] - 1)

                # è®¡ç®—å…¶ä»–æŒ‡æ ‡
                returns = []
                for i in range(1, len(values)):
                    ret = values[i] / values[i - 1] - 1
                    returns.append(ret)

                if returns:
                    annual_return = np.mean(returns) * 252
                    volatility = np.std(returns) * np.sqrt(252)
                    sharpe = (annual_return - self.risk_free_rate) / volatility if volatility > 0 else 0
                    max_dd = self._calculate_max_drawdown(values)
                    var95 = -np.percentile(returns, 5)
                    worst = [r for r in returns if r <= np.percentile(returns, 5)]
                    cvar95 = -np.mean(worst) if worst else 0
                    calmar = annual_return / max_dd if max_dd > 0 else 0
                    
                else:
                    annual_return = volatility = sharpe = max_dd = var95 = cvar95 = calmar = 0

                performance_data.append({
                    'Method': method_name,
                    'Total_Return': total_return,
                    'Annual_Return': annual_return,
                    'Volatility': volatility,
                    'Sharpe_Ratio': sharpe,
                    'Max_Drawdown': max_dd,
                    'VaR95%': var95,
                    'CVaR95%': cvar95,
                    'Calmar_Ratio': calmar
                })

        if performance_data:
            perf_df = pd.DataFrame(performance_data)
            perf_file = results_dir / f"simple_xgb_performance_{timestamp}.csv"
            perf_df.to_csv(perf_file, index=False)
            print(f"âœ… æ€§èƒ½ç»“æœ: {perf_file}")

            # æ˜¾ç¤ºç»“æœ
            print("\nğŸ“Š æœ€ç»ˆæ€§èƒ½å¯¹æ¯”:")
            for _, row in perf_df.iterrows():
                print((
                    f"  {row['Method']}: "
                    f"æ€»æ”¶ç›Š={row['Total_Return']:.1%}, "
                    f"Annual={row['Annual_Return']:.2%}, "
                    f"Vol={row['Volatility']:.2%}, "
                    f"Sharpe={row['Sharpe_Ratio']:.3f}, "
                    f"VaR95%={row['VaR95%']:.2%}, "
                    f"CVaR95%={row['CVaR95%']:.2%}, "
                    f"Calmar={row['Calmar_Ratio']:.3f}"
                ))

            # æå–ç­–ç•¥çš„æ—¥åº¦æ”¶ç›Šè¿›è¡Œæ˜¾è‘—æ€§æ£€éªŒ
            eq_nv = np.array(self.portfolio_results['equal_weight']['portfolio_values'])
            xgb_nv = np.array(self.portfolio_results['simple_xgb_enhanced']['portfolio_values'])
            mom_nv = np.array(self.portfolio_results['xgb_momentum']['portfolio_values'])
            rp_nv = np.array(self.portfolio_results['xgb_risk_parity']['portfolio_values'])
            
            # è®¡ç®—æ”¶ç›Šç‡
            eq_r = np.diff(eq_nv) / eq_nv[:-1]
            xgb_r = np.diff(xgb_nv) / xgb_nv[:-1]
            mom_r = np.diff(mom_nv) / mom_nv[:-1]
            rp_r = np.diff(rp_nv) / rp_nv[:-1]
            
            # é…å¯¹ t-test
            try:
                t1, p1 = stats.ttest_rel(xgb_r, eq_r)
                t2, p2 = stats.ttest_rel(mom_r, eq_r)
                t3, p3 = stats.ttest_rel(rp_r, eq_r)
                
                print("\nâ€”â€” æ˜¾è‘—æ€§æ£€éªŒ â€”â€”")
                print(f"XGBoost vs equal_weight: t={t1:.2f}, p={p1:.3f}")
                print(f"XGBoost_momentum vs equal_weight: t={t2:.2f}, p={p2:.3f}")
                print(f"XGBoost_risk_parity vs equal_weight: t={t3:.2f}, p={p3:.3f}")
            except Exception as e:
                print(f"æ˜¾è‘—æ€§æ£€éªŒå¤±è´¥: {e}")

        # å¯¼å‡ºä¿¡å·å†å²
        if self.signal_history:
            signal_data = []
            for date, data in self.signal_history.items():
                signals = data['signals']
                for ticker, signal in signals.items():
                    signal_data.append({
                        'Date': date,
                        'Ticker': ticker,
                        'Signal': signal,
                        'Active_Count': data['active_count']
                    })
            
            if signal_data:
                signal_df = pd.DataFrame(signal_data)
                signal_file = results_dir / f"xgb_signals_{timestamp}.csv"
                signal_df.to_csv(signal_file, index=False)
                print(f"âœ… ä¿¡å·å†å²: {signal_file}")

    def _calculate_max_drawdown(self, values):
        """è®¡ç®—æœ€å¤§å›æ’¤"""
        if len(values) < 2:
            return 0

        peak = values[0]
        max_dd = 0

        for value in values[1:]:
            if value > peak:
                peak = value
            else:
                dd = (peak - value) / peak
                max_dd = max(max_dd, dd)

        return max_dd


def run_simple_xgb_optimization():
    """è¿è¡Œç®€å•XGBoostä¼˜åŒ–"""
    print("ğŸš€ å¯åŠ¨ç®€å•XGBoostä¼˜åŒ–...")

    optimizer = SimpleXGBOptimizer(
        data_path="./",
        rebalance_freq=63,  # å­£åº¦
        min_history=252,
        transaction_cost=0.001
    )

    # è¿è¡Œä¼˜åŒ–
    results = optimizer.run_simple_optimization(max_periods=15)

    print("\nğŸ‰ ç®€å•XGBoostä¼˜åŒ–å®Œæˆ!")
    print("âœ… é¿å…äº†å¤æ‚çš„æ•°å€¼ä¼˜åŒ–")
    print("âœ… ä½¿ç”¨ç¨³å®šçš„æƒé‡åˆ†é…æ–¹æ³•")
    print("âœ… XGBoostä¿¡å·æ­£å¸¸å·¥ä½œ")
    print("âœ… é›†æˆäº†é˜ˆå€¼ä¼˜åŒ–å’Œæ¦‚ç‡æ ¡å‡†")
    print("âœ… æ”¯æŒå››ç§ç­–ç•¥å¯¹æ¯”")

    return optimizer


if __name__ == "__main__":
    optimizer = run_simple_xgb_optimization()